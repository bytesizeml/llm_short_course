{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## This in-class exercise should get you familiar with a) setting up the API for Chat GPT b) using it for prompting and c) Also generating data labeled by ChatGPT that can be used for down-stream tasks and d)Keyword extraction and Keyword based search"
      ],
      "metadata": {
        "id": "CulHydAiREK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Libraries"
      ],
      "metadata": {
        "id": "pSxZWcAR38gB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PmBvrSE3qRO",
        "outputId": "245052bf-e389-40fc-f914-7e470e4390d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.2.3-py3-none-any.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.3/220.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Collecting httpcore (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 openai-1.2.3\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install openai\n",
        "!pip3 install python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Local Directory to a Google Drive Location that you specify"
      ],
      "metadata": {
        "id": "lEq6pYj8hJW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "import os\n",
        "print(os.system('ls'))\n",
        "\n",
        "os.chdir(os.curdir + \"/drive/MyDrive/Colab_Notebooks_LLM_2023\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5I31cpF3xOV",
        "outputId": "f91a3da6-d2f0-46fd-c42a-4e2fdd64576a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGJlfQv6iPe-",
        "outputId": "aa860c89-ab24-4351-fa49-b2fc794cc2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " LLM_prompting.ipynb\t\t\t\t      Nov12_inclass_exercise.ipynb\n",
            "'Nov11_In_Class_Assignment ECE UW, PMP course 2023'   openai_api_key_llm_2023.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OPEN AI ACCESS\n",
        "For openAI API access, you first need to ensure you have set up the API credentials for ChatGPT. Head over to https://chat.openai.com/ to see if you can access the chat. Next, if you have set up your API keys: you will find them here: https://platform.openai.com/api-keys\n",
        "If not, you can take the time to set it up before proceeding.\n",
        "\n",
        "Once you have the API key - add the key to the open_ai_key_file location below."
      ],
      "metadata": {
        "id": "GOyGGTuC4Ty9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "open_ai_key_file = \"openai_api_key_llm_2023.txt\"\n",
        "with open(open_ai_key_file, \"r\") as f:\n",
        "  for line in f:\n",
        "    OPENAI_KEY = line\n",
        "    break\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "openai.api_key  = OPENAI_KEY"
      ],
      "metadata": {
        "id": "peQ_A0Hq4MGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Response from OPEN AI"
      ],
      "metadata": {
        "id": "kTPxs1J-66Dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "pQ6Z8EVl5kzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visual Steps Task based on a given example"
      ],
      "metadata": {
        "id": "VdtLCUaPzXCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"Make the bed steps are :                                                                                                                                                                            put the sheet on the bed\n",
        "insert the quilt into the quilt cover\n",
        "put the quilt on the bed\n",
        "insert the pillow into the pillow cover\n",
        "put the pillow on the bed.   Similarly, provide the steps of \"fixing the hair\" that are visually seen. No need of explaining each step.\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "nvoXyqiVybXx",
        "outputId": "346b57dd-25e4-4c6d-cb34-8970aa192771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1. Comb or brush the hair\\n2. Style or arrange the hair as desired\\n3. Use hair products (if desired)\\n4. Secure the hair with hair accessories (if desired)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise: Check the response given through Chat interface for the above prompt. Do you get a similar answer?\n",
        "The chat interface can be accessed at: https://chat.openai.com/"
      ],
      "metadata": {
        "id": "kMylZ9USOvv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt for KeyWord Extraction"
      ],
      "metadata": {
        "id": "S9j9YoL889EL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_keywords_from_text(text_list):\n",
        "  if not isinstance(text_list,list):\n",
        "    text_list = [text_list]\n",
        "\n",
        "  num_strings = len(text_list)\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "  Here's a list of \"\"\" + str(num_strings) + f\"\"\" string given by the text delimited by 3 quotes: ```{text_list}```.\n",
        "  For each string in the list, generate at least two key words and at most 3 key words.\n",
        "  Return result as a list.\n",
        "  The key word should be relevant to the text\n",
        "  and each key word can capture a different popular theme of interest for wisdom\n",
        "  seekers.\n",
        "  The key word doesn't have to be present in the text. Also key word shouldn't\n",
        "  have a space in it.\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  responses = get_completion(prompt)\n",
        "\n",
        "  return responses"
      ],
      "metadata": {
        "id": "MwIBDdfH6nPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "  BECOMING DEFENSELESS\n",
        "\n",
        "Whenever a boundary is broken, it creates some fear. The fear creates dislike. This dislike puts us back in the boundary. And to keep yourself in the boundary you put forth defenses. When you try to defend your position, it is such a stress, isn't it? And every time you try to defend your position it makes you more and more weak.\n",
        "\n",
        "On the path, people even use the Knowledge as a defense against criticism! Don't use Knowledge as a defense.\n",
        "\n",
        "The Knowledge is like an umbrella for you -- a shelter, not a weapon. Of course, sometimes \"Don't use Knowledge as a weapon\" becomes an excuse not to be in Knowledge! (Laughter)\n",
        "\n",
        "I say, drop all your defenses. Anybody can make a mistake. Even you!\n",
        "\n",
        "Don't defend your mistakes. Just accept them and move on. When you are totally defenseless, that's when you'll be strong.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "print(get_keywords_from_text(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAQGAUZB_6sS",
        "outputId": "c7b4c46c-e41c-4538-ea0d-f53f93cb7284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['boundary', 'defense', 'knowledge']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Data\n",
        "\n",
        "1. Download 100 quotes from here: https://gist.githubusercontent.com/robatron/a66acc0eed3835119817/raw/77493d3ddf69fbd9d69997e22e1a7c6c70c8bdf2/quotes.txt and save it as quotes_100.txt\n",
        "\n",
        "2. Download 400 quotes from here: https://raw.githubusercontent.com/erossignon/qod4outlook/master/quotes.txt and save it as quotes_400.txt"
      ],
      "metadata": {
        "id": "roZRRIqzc7Jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O quotes_100.txt https://gist.githubusercontent.com/robatron/a66acc0eed3835119817/raw/77493d3ddf69fbd9d69997e22e1a7c6c70c8bdf2/quotes.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXRR_3AfPSSf",
        "outputId": "d5df0a06-9524-4c25-82ec-e34cad8fb24e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-12 15:54:09--  https://gist.githubusercontent.com/robatron/a66acc0eed3835119817/raw/77493d3ddf69fbd9d69997e22e1a7c6c70c8bdf2/quotes.txt\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10641 (10K) [text/plain]\n",
            "Saving to: ‘quotes_100.txt’\n",
            "\n",
            "\rquotes_100.txt        0%[                    ]       0  --.-KB/s               \rquotes_100.txt      100%[===================>]  10.39K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-12 15:54:09 (67.0 MB/s) - ‘quotes_100.txt’ saved [10641/10641]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head quotes_100.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pm63qldPaaT",
        "outputId": "cf74dbe5-a553-45af-cea0-3779141609ad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If you want to achieve greatness stop asking for permission. ~Anonymous\n",
            "Things work out best for those who make the best of how things work out. ~John Wooden\n",
            "To live a creative life, we must lose our fear of being wrong. ~Anonymous\n",
            "If you are not willing to risk the usual you will have to settle for the ordinary. ~Jim Rohn\n",
            "Trust because you are willing to accept the risk, not because it's safe or certain. ~Anonymous\n",
            "Take up one idea. Make that one idea your life - think of it, dream of it, live on that idea. Let the brain, muscles, nerves, every part of your body, be full of that idea, and just leave every other idea alone. This is the way to success. ~Swami Vivekananda\n",
            "All our dreams can come true if we have the courage to pursue them. ~Walt Disney\n",
            "Good things come to people who wait, but better things come to those who go out and get them. ~Anonymous\n",
            "If you do what you always did, you will get what you always got. ~Anonymous\n",
            "Success is walking from failure to failure with no loss of enthusiasm. ~Winston Churchill\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "ddyQUoO_-d9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "#In-class Exercise\n",
        "##################\n",
        "def load_all_data(file_path):\n",
        "  \"\"\"\n",
        "  Load quotes\n",
        "  \"\"\"\n",
        "  quotes = [] # How do you want to store the quotes and the authors - List? tuples? dictionary? Make a choice\n",
        "  with open(file_path, \"r\") as f:\n",
        "    for line in f:\n",
        "      quote, author = line.split(\"~\")\n",
        "      quotes.append((quote.strip(\" \"),author.strip(\"\\n\")))\n",
        "\n",
        "\n",
        "  return quotes\n",
        "\n",
        "\n",
        "quotes = load_all_data(\"quotes_100.txt\")\n",
        "quotes[:5] # Look at first five quotes"
      ],
      "metadata": {
        "id": "4qOQOK_y-fov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b23cea14-170b-4b1b-df3d-093d2e92109a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('If you want to achieve greatness stop asking for permission.', 'Anonymous'),\n",
              " ('Things work out best for those who make the best of how things work out.',\n",
              "  'John Wooden'),\n",
              " ('To live a creative life, we must lose our fear of being wrong.',\n",
              "  'Anonymous'),\n",
              " ('If you are not willing to risk the usual you will have to settle for the ordinary.',\n",
              "  'Jim Rohn'),\n",
              " (\"Trust because you are willing to accept the risk, not because it's safe or certain.\",\n",
              "  'Anonymous')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YnVrbZXbss8",
        "outputId": "93eb27b3-0065-4df5-9bed-6b06868cf14d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_file_path  quotes_100.txt  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Application 0"
      ],
      "metadata": {
        "id": "8ci1YIPqQei1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##In-class Exercise\n",
        "\n",
        "def print_anonymous_quotes(num_quotes=3):\n",
        "  \"\"\"\n",
        "  Print k anonymous quotes at random from the quotes you just loaded in the previous code block.\n",
        "  Here k = num_quotes passed in by you\n",
        "  \"\"\"\n",
        "\n",
        "  ### Your code here\n",
        "\n",
        "\n",
        "## Test\n",
        "print_anonymous_quotes(4) # Should print 4 anonymous quotes at random\n"
      ],
      "metadata": {
        "id": "ZVIk4QIrQlSg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use ChatGPT to Generate Keywords for Hundreds of quotes"
      ],
      "metadata": {
        "id": "-h62Uyac__pK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def generate_keywords_for_single_text(text):\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "  Here's a text  de-limited by 3 quotes: ```{text}```.\n",
        "  Generate three distinct keywords that capture the most important topics in the text.\n",
        "  The key word doesn't have to be present in the text. Also key word shouldn't\n",
        "  have a space in it. Make sure the key word is just one word and not two words joined.\n",
        "  \"\"\"\n",
        "\n",
        "  #Make sure the key word is just one word and not two words joined.\n",
        "\n",
        "  response = get_completion(prompt)\n",
        "\n",
        "  return response\n",
        "\n",
        "\n",
        "##################\n",
        "#In-class Exercise (Same as Applicatoin 1 below)\n",
        "##################\n",
        "def generate_keywords_for_all_text(input_quotes):\n",
        "  \"\"\"\n",
        "  Generate keywords for all quotes in a given text file.\n",
        "  The keywords should be generated in one call of this function and should not break\n",
        "  \"\"\"\n",
        "\n",
        "  # Your code here\n",
        "  # How should the input_quotes look like - Choose an appropriate data structure (goes back to how you load the data)\n",
        "  # The output should return a data structure that has keywords for all the quotes\n",
        "\n",
        "  pass"
      ],
      "metadata": {
        "id": "_zQz9ayg9hgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Application 1:\n",
        "## Generating Keywords for Hundreds of texts"
      ],
      "metadata": {
        "id": "E6wOTVbJ9Hve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "#In-class Exercise\n",
        "##################\n",
        "\n",
        "# 1. Pick a file_path e.g. quotes_100.txt or quotes_400.txt that you downloaded earlier\n",
        "\n",
        "# 2. Pass in the file_path for quotes and load the quotes to memory\n",
        "# input_quotes = load_all_data(file_path)\n",
        "\n",
        "# 3. Generate key words for all the input_quotes and store it in an appopriate data structure\n",
        "# quotes_keywords_dict = generate_keywords_for_all_text(input_quotes)"
      ],
      "metadata": {
        "id": "5M4A2B4O7X--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Application 2: Keyword Search\n",
        "\n",
        "Return random quotes based on a keyword input by the user. The keyword should be one of the keywords generated by ChatGPT in Application 1."
      ],
      "metadata": {
        "id": "GsiiNiIpf7q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def keyword_search(input_keyword, num_quotes=3):\n",
        "  \"\"\"\n",
        "  Generates num_quotes random quotes given an input keyword.\n",
        "  The input_keyword must be valid and one of the keywords generated by ChatGPT in application 1.\n",
        "  \"\"\"\n",
        "\n",
        "  ### Your Code HERE!\n",
        "\n",
        "\n",
        "# TEST YOUR CODE\n",
        "# input_keyword = \"test\"\n",
        "# quotes = keyword_search(input_keyword)\n",
        "# print(quotes)"
      ],
      "metadata": {
        "id": "zWNOTCqwgSis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Application 3: Build a local web app that showcases generating quotes based on keywords"
      ],
      "metadata": {
        "id": "eSbqgOGMlpNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Use Streamlit code from Assignment 0 or on the web to generate a local webapp\n",
        "## The webapp takes in: Keyword and outputs: quotes related to the keyword\n",
        "\n",
        "## 1. You can use the code from Application 2 and copy it to your laptop machine\n",
        "## and call it something e.g. streamlit_demo.py (i.e. switch from google colab to your laptop IDE for the webpage task)\n",
        "## Include the streamlit code for search bar, taking in input and returning results, etc to this python file\n",
        "\n",
        "## 2. execute \"streamlit run streamlit_demo.py\" and if all went well it should display a local webpage that\n",
        "## you can search for quotes on"
      ],
      "metadata": {
        "id": "DQVhTluHDmGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Application 5: Have your local web app support any keyword! (If time permits)\n",
        "\n",
        "This is an extension of Application 2 and Application 3. Given a key word, pick the nearest keyword from your keywords list that you generated earlier and return quotes from the nearest one.\n",
        "\n",
        "Modify the keyword_search function from Application 2 here to support any keyword (hint: use embeddings based search to retrieve nearest keyword)"
      ],
      "metadata": {
        "id": "7QqqIw2YmZHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nearest_keyword_search(input_keyword, num_quotes=3):\n",
        "  \"\"\"\n",
        "  Generates num_quotes random quotes given an input keyword.\n",
        "  The input_keyword can be anything but you can find the closest keyword from the ones that are available\n",
        "  and then return appropriate quotes\n",
        "  \"\"\"\n",
        "\n",
        "  ### Your Code HERE!\n",
        "\n",
        "\n",
        "# TEST YOUR CODE\n",
        "# input_keyword = \"test\"\n",
        "# quotes = keyword_search(input_keyword)\n",
        "# print(quotes)"
      ],
      "metadata": {
        "id": "SqBJXz66mmJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SRD1fpDMm0Zl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}